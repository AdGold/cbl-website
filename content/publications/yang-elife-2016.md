---
date: 2020-12-01T17:22:18Z
title: "Active sensing in the categorization of visual patterns"
authors: ["S-CH Yang", "ml468<sup>*</sup>", "dw304<sup>*</sup>"]
year: "2016"
publication: "eLife"
type: "journal" # journal / rconf (i.e. refereed conference) / uconf (i.e. unrefereed conference) / thesis / preprint / workshop
link: "https://elifesciences.org/content/5/e12215"
file: ""
code: "https://github.com/firekg/BAS"
illustration: "yang-elife-2016.jpg"
selected: false # (ignore for now; in the future we might want to add a "Selected publications" section)
labs: ["lengyel"]
draft: false
---

<!-- Abstract here please (you can use Markdown) -->

Interpreting visual scenes typically requires us to accumulate information from
multiple locations in a scene. Using a novel gaze-contingent paradigm in a
visual categorization task, we show that participants' scan paths follow an
active sensing strategy that incorporates information already acquired about
the scene and knowledge of the statistical structure of patterns. Intriguingly,
categorization performance was markedly improved when locations were revealed
to participants by an optimal Bayesian active sensor algorithm. By using a
combination of a Bayesian ideal observer and the active sensor algorithm, we
estimate that a major portion of this apparent suboptimality of fixation
locations arises from prior biases, perceptual noise and inaccuracies in eye
movements, and the central process of selecting fixation locations is around
70% efficient in our task. Our results suggest that participants select eye
movements with the goal of maximizing information about abstract categories
that require the integration of information from multiple locations.




