---
date: 2020-12-01T17:30:12Z
title: "Goal-directed decision making with spiking neurons"
authors: ["jf517", "ml468"]
year: "2016"
publication: "Journal of Neuroscience"
type: "journal"
link: "http://www.jneurosci.org/content/36/5/1529.abstract"
file: "" 
code: "https://github.com/j-friedrich/Goal-directed_decision_making_with_spiking_neurons"
illustration: ""
selected: false
labs: ["lengyel"]
draft: false
---

<!-- Abstract here please (you can use Markdown) -->

Behavioral and neuroscientific data on reward-based decision making point to a
fundamental distinction between habitual and goal-directed action selection.
The formation of habits, which requires simple updating of cached values, has
been studied in great detail, and the reward prediction error theory of
dopamine function has enjoyed prominent success in accounting for its neural
bases. In contrast, the neural circuit mechanisms of goal-directed decision
making, requiring extended iterative computations to estimate values online,
are still unknown. Here we present a spiking neural network that provably
solves the difficult online value estimation problem underlying goal-directed
decision making in a near-optimal way and reproduces behavioral as well as
neurophysiological experimental data on tasks ranging from simple binary choice
to sequential decision making. Our model uses local plasticity rules to learn
the synaptic weights of a simple neural network to achieve optimal performance
and solves one-step decision-making tasks, commonly considered in
neuroeconomics, as well as more challenging sequential decision-making tasks
within 1 s. These decision times, and their parametric dependence on task
parameters, as well as the final choice probabilities match behavioral data,
whereas the evolution of neural activities in the network closely mimics neural
responses recorded in frontal cortices during the execution of such tasks. Our
theory provides a principled framework to understand the neural underpinning of
goal-directed decision making and makes novel predictions for sequential
decision-making tasks with multiple rewards.


